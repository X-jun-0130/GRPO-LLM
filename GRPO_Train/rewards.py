"""Reward functions for GRPO training."""
import re
from math_verify import parse, verify
import time
from reward_model_api import text_generate
import json

strtime = time.strftime("%Y%m%d")


verifier_prompt:str = '''
ä½ æ˜¯ä¸€åä¸“ä¸šçš„è¯„ä¼°ä¸“å®¶ï¼Œéœ€æ ¹æ®ä»¥ä¸‹å››ä¸ªæ ¸å¿ƒè¦ç´ æ¥å¯¹ã€Œé¢„æµ‹ç­”æ¡ˆã€è¿›è¡Œè´¨é‡è¯„ä¼°ï¼š

- **å¯¹è¯å†å²**ï¼ˆä¸Šä¸‹æ–‡ä¿¡æ¯ï¼‰
- **å½“å‰é—®é¢˜**ï¼ˆç”¨æˆ·æå‡ºçš„å…·ä½“è¯·æ±‚ï¼‰
- **ä¼˜ç§€ç­”æ¡ˆ**ï¼ˆç»è¿‡å®¡æ ¸çš„é«˜è´¨é‡å‚è€ƒç­”æ¡ˆï¼‰
- **é¢„æµ‹ç­”æ¡ˆ**ï¼ˆå¾…è¯„ä¼°çš„ç­”æ¡ˆï¼‰

### â­ è¯„åˆ†æ ‡å‡†ï¼š
- **æ»¡åˆ†**ï¼šæ»¡åˆ†100åˆ†ï¼Œè¡¨ç¤ºã€Œé¢„æµ‹ç­”æ¡ˆã€è´¨é‡é«˜ï¼Œä¸ã€Œä¼˜ç§€ç­”æ¡ˆã€ç›¸å½“æˆ–æ¥è¿‘ï¼Œæ»¡è¶³ç”¨æˆ·éœ€æ±‚ï¼›
- **æ‰£åˆ†**ï¼šæ ¹æ®ã€Œé¢„æµ‹ç­”æ¡ˆã€å­˜åœ¨çš„é—®é¢˜---å¹»è§‰ã€é—æ¼ã€é”™è¯¯æˆ–æ— æ³•æ»¡è¶³ç”¨æˆ·éœ€æ±‚ç­‰ï¼Œè¿›è¡Œç›¸åº”çš„æ‰£åˆ†ï¼›

> æ³¨æ„ï¼šã€Œä¼˜ç§€ç­”æ¡ˆã€å·²é€šè¿‡ä¸¥æ ¼å®¡æ ¸ï¼Œå…¶è´¨é‡è¢«è®¤ä¸ºæ˜¯é«˜æ ‡å‡†çš„ï¼Œå¯ä½œä¸ºåˆ¤æ–­åŸºå‡†ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„è¾“å‡ºä½ çš„è¯„ä¼°ç»“æœï¼š

---

### ğŸ“œ å¯¹è¯å†å²ï¼ˆæŒ‰æ—¶é—´é¡ºåºæ’åˆ—ï¼Œä»æœ€æ—©åˆ°æœ€æ–°ï¼‰
```
{æ’å…¥å¯¹è¯å†å²}
```

### â“ å½“å‰é—®é¢˜
```
{æ’å…¥åŸå§‹é—®é¢˜}
```

### âœ… ä¼˜ç§€ç­”æ¡ˆï¼ˆå‚è€ƒç­”æ¡ˆï¼‰
```
assistantï¼š{æ’å…¥ä¼˜ç§€ç­”æ¡ˆ}
```

### ğŸ¤– é¢„æµ‹ç­”æ¡ˆï¼ˆå¾…è¯„ä¼°ç­”æ¡ˆï¼‰
```
assistantï¼š{æ’å…¥å¾…è¯„ä¼°ç­”æ¡ˆ}
```

---

### ğŸ“Š è¯„ä¼°åˆ†æ

[åœ¨æ­¤å¤„è¿›è¡Œé€é¡¹å¯¹æ¯”åˆ†æ]

---

### ğŸ“Œ é¢„æµ‹ç­”æ¡ˆè¯„ä¼°åˆ†æ•°

\\boxed{é¢„æµ‹ç­”æ¡ˆè¯„ä¼°åˆ†æ•°}

---
'''


def extract_evaluation_score(response: str) -> float:
    """
    ä»æ¨¡å‹å›å¤ä¸­æå–è¯„ä¼°åˆ†æ•°ï¼ˆæœ€åä¸€ä¸ª\\boxed{}ä¸­çš„0-100åˆ†æ•°å­—ï¼‰ï¼Œ
    å¤„ç†æ•´æ•°å’Œå°æ•°æ ¼å¼ï¼Œå¹¶å°†ç»“æœå‹ç¼©åˆ°0-1èŒƒå›´
    
    å‚æ•°:
        response: åŒ…å«è¯„ä¼°åˆ†æ•°çš„æ–‡æœ¬å­—ç¬¦ä¸²
        
    è¿”å›:
        æå–å¹¶å¤„ç†åçš„åˆ†æ•°ï¼ˆ0.0-1.0ä¹‹é—´çš„æµ®ç‚¹æ•°ï¼‰
    """
    # åŒ¹é…æ‰€æœ‰\boxed{}å†…å®¹
    boxes = re.findall(r'\\boxed\{([^}]*)\}', response)
    
    if not boxes:
        return 0.0
    
    # å–æœ€åä¸€ä¸ªboxedå†…å®¹
    last_box = boxes[-1].strip()
    
    # æ”¹è¿›çš„æ•°å­—åŒ¹é…ï¼šæ”¯æŒæ•´æ•°å’Œå°æ•°æ ¼å¼ï¼ˆå¦‚95, 96.5, 85åˆ†ï¼‰
    score_match = re.search(
        r'(\d{1,3}(?:\.\d{1,2})?)\s*(?:åˆ†)?\b', 
        last_box
    )
    
    if score_match:
        try:
            score = float(score_match.group(1))
            # å¤„ç†åˆ†æ•°èŒƒå›´
            if score <= 40.0:  # ä½åˆ†ç›´æ¥å½’é›¶
                return 0.0
            elif score > 100.0:  # è¶…ç™¾åˆ†åˆ¶å¤„ç†
                return min(score / 100.0, 1.0)
            else:
                return score / 100.0
        except (ValueError, TypeError):
            return 0.0
    
    # é¢å¤–å°è¯•åŒ¹é…å¸¦ç­‰å·çš„åˆ†æ•°ï¼ˆå¦‚"=96.5"ï¼‰
    equals_match = re.search(r'=\s*(\d{1,3}(?:\.\d{1,2})?)\b', last_box)
    if equals_match:
        try:
            score = float(equals_match.group(1))
            return max(0.0, min(score / 100.0, 1.0)) if score > 40.0 else 0.0
        except (ValueError, TypeError):
            pass
    
    return 0.0


def think_format_reward(content):
    """Reward function that checks if the completion has a specific format."""
    pattern = r"^<think>\n.*\n</think>\n.+"
    flags = re.DOTALL  # å…è®¸ . åŒ¹é…æ¢è¡Œç¬¦
    required_tags = ['<think>', '</think>']
    
    # æ£€æŸ¥æ•´ä½“ç»“æ„æ˜¯å¦ç¬¦åˆæ­£åˆ™è¡¨è¾¾å¼
    struct_match = re.fullmatch(pattern, content, flags=flags)
    if not struct_match:
        return False

    # æ£€æŸ¥æ¯ä¸ªæ ‡ç­¾æ˜¯å¦æ°å¥½å‡ºç°ä¸€æ¬¡
    tag_counts = [content.count(tag) for tag in required_tags]
    if all(count == 1 for count in tag_counts):
        return True
    else:
        return False


def get_reward(message, output, target, task, limit):
    if task == "quality-control":
        matches_text1 = re.findall(r'(true|false)', output)
        matches_text2 = re.findall(r'(true|false)', target)
        if matches_text1 == matches_text2:
            reward = 1.0
        else:
            reward = 0.0
                   
    elif task == 'math':
        answer = parse(output)
        reward = float(verify(answer, parse(target)))
        
    elif task == 'choice':
        matches_text1 = re.findall(r'\\boxed\{(?:\\text\{)?([ABCDEFG])(?:\..*)?(?:\})?\}', output)
        matches_text2 = re.findall(r'\\boxed\{(?:\\text\{)?([ABCDEFG])(?:\..*)?(?:\})?\}', target)
        if matches_text1 == matches_text2:
            reward = 1.0
        else:
            reward = 0.0
    
    elif task == 'MedCalc-Bench':
        answer = parse(output)[0]
        if limit[0] <= answer <= limit[1]:
            reward = 1.0
        else:
            reward = 0.0
             
    else:
        prompt = verifier_prompt.strip()

        if len(message)>=3:
            chathistory = message[:-1]
            history  = '\n'.join([k['role']+'ï¼š'+k['content'].strip() for k in chathistory])
            prompt = prompt.replace('{æ’å…¥å¯¹è¯å†å²}', history)
            question = 'userï¼š' + message[-1]['content'].strip()
        else:
            prompt = prompt.replace('{æ’å…¥å¯¹è¯å†å²}', 'æ— ')
            question = '\n'.join([k['role']+'ï¼š'+k['content'].strip() for k in message])

        prompt = prompt.replace('{æ’å…¥åŸå§‹é—®é¢˜}', question.strip())
        prompt = prompt.replace('{æ’å…¥ä¼˜ç§€ç­”æ¡ˆ}', target.strip())
        prompt = prompt.replace('{æ’å…¥å¾…è¯„ä¼°ç­”æ¡ˆ}', output.strip())
        
        # æ¨¡å‹å¤„ç†æµç¨‹
        chat = [{"role": "user", "content": prompt}]
        verifier_answer = text_generate(chat)

        reward = extract_evaluation_score(verifier_answer.strip())
            
        try:
            with open(f'/workspace/LLM-Train/LLM-RL/LLM-veRL/log_date/{strtime}-model_verifier.json', 'a+', encoding='utf-8') as target_file:
                target_file.write(json.dumps({'question':question,'solution':target, 'output':output, 'generated':verifier_answer, 'reward_score':reward}, ensure_ascii=False) + '\n')
        except:
            pass
    
    return reward


def calculate_reward(output_length):
    soft, hard, max_len = 4096, 8192, 24*1024
    min_reward = 0.1
    
    if output_length <= soft:
        return 1.0
    
    #æ¸©å’Œçº¿æ€§æƒ©ç½š ä»1.0çº¿æ€§é™è‡³0.9
    if output_length <= hard:
        ratio = (output_length - soft) / (hard - soft)
        return round(1.0 - 0.1 * ratio, 4)
    
    #åŠ é€Ÿéçº¿æ€§æƒ©ç½š äºŒæ¬¡æ–¹åŠ é€Ÿä¸‹é™æ›²çº¿ï¼š0.9 -> 0.1
    ratio = (output_length - hard) / (max_len - hard)
    reward = 0.9 - 0.8 * (ratio ** 2)
    return round(max(reward, min_reward), 4)


def accuracy_reward(messages, content, solution, task, limit, output_length):
    """Reward function that checks if the completion is the same as the ground truth."""
    # Reward 1 if the content is the same as the ground truth, 0 otherwise
    # Shorter correct solutions are rewarded more than longer ones. add cosine
    
    try:
        if not content.endswith('<|im_end|>'):
            return 0.0
        else:
            content = content.replace('<|im_end|>', '')
            output = content.strip()
            base_reward = get_reward(messages, output, solution, task, limit)
            return base_reward
          
    except Exception:  # if it fails for any reason, return 0.0
        return 0.0
